{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c02c96d",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2196621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Abdalrhman\n",
      "[nltk_data]     Morsi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from pyarabic.araby import strip_tashkeel\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import Callback\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6037c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.experimental.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98102389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e4c9111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008235a9",
   "metadata": {},
   "source": [
    "# Read The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e692eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_excel('Data/All_Stories.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d70fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for sheet_name, dataframe in dfs.items():\n",
    "    df = pd.concat([df , dfs[f\"{sheet_name}\"]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67a4276c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f06aa998054e11eba66e646e69d991ea</td>\n",
       "      <td>\"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 23:19</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1cf1b9c054e11ebb718646e69d991ea</td>\n",
       "      <td>مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 07:26</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2d282a4054e11eb800f646e69d991ea</td>\n",
       "      <td>فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 04:00</td>\n",
       "      <td>عفيفة الحسينات*</td>\n",
       "      <td>تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f3f46cac054e11eba403646e69d991ea</td>\n",
       "      <td>\"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 02:00</td>\n",
       "      <td>حاورَها: وائل بورشاشن</td>\n",
       "      <td>مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f50f0476054e11eba31b646e69d991ea</td>\n",
       "      <td>مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"</td>\n",
       "      <td>الخميس 01 أكتوبر 2020 - 19:40</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>a74f908a055c11eb8ce2646e69d991ea</td>\n",
       "      <td>تكريم \"تُحفة مَناقب شرفاء وزان\" في جامعة فرنسية</td>\n",
       "      <td>الثلاثاء 24 دجنبر 2019 - 20:05</td>\n",
       "      <td>هسبريس - مصطفى شاكري</td>\n",
       "      <td>أطروحة جديدة تُعنى بدراسة الأبعاد السيميائية ل...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>a8579f76055c11eb9627646e69d991ea</td>\n",
       "      <td>إسبانيا تردّ على المغرب بنشر طائرات \"إف 18\" فو...</td>\n",
       "      <td>الثلاثاء 24 دجنبر 2019 - 18:00</td>\n",
       "      <td>هسبريس - عبد السلام الشامخ</td>\n",
       "      <td>تزامناً مع توجّه المغرب لترسيم حدوده في المياه...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>a9362062055c11ebaf97646e69d991ea</td>\n",
       "      <td>لجنة النموذج التنموي تضع \"ميثاق قواعد الاشتغال\"</td>\n",
       "      <td>الثلاثاء 24 دجنبر 2019 - 13:15</td>\n",
       "      <td>هسبريس - و.م.ع</td>\n",
       "      <td>قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>aa1cef2e055c11eb8ef8646e69d991ea</td>\n",
       "      <td>ضعف القدرات البشرية والبنيات المؤسساتية يبطئ ا...</td>\n",
       "      <td>الثلاثاء 24 دجنبر 2019 - 13:00</td>\n",
       "      <td>هسبريس - يوسف لخضر</td>\n",
       "      <td>اختُتمت، السبت الماضي بمدينة أكادير، أشغال الم...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>aabdd852055c11ebbba8646e69d991ea</td>\n",
       "      <td>الشرطة تبرز خطوات تطوير الحياة المهنية الأمنية</td>\n",
       "      <td>الثلاثاء 24 دجنبر 2019 - 12:33</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>كشفت المديرية العامة للأمن الوطني عن حصيلة عمل...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0      f06aa998054e11eba66e646e69d991ea   \n",
       "1      f1cf1b9c054e11ebb718646e69d991ea   \n",
       "2      f2d282a4054e11eb800f646e69d991ea   \n",
       "3      f3f46cac054e11eba403646e69d991ea   \n",
       "4      f50f0476054e11eba31b646e69d991ea   \n",
       "...                                 ...   \n",
       "10995  a74f908a055c11eb8ce2646e69d991ea   \n",
       "10996  a8579f76055c11eb9627646e69d991ea   \n",
       "10997  a9362062055c11ebaf97646e69d991ea   \n",
       "10998  aa1cef2e055c11eb8ef8646e69d991ea   \n",
       "10999  aabdd852055c11ebbba8646e69d991ea   \n",
       "\n",
       "                                                   title  \\\n",
       "0         \"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء   \n",
       "1           مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران   \n",
       "2      فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...   \n",
       "3      \"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...   \n",
       "4            مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"   \n",
       "...                                                  ...   \n",
       "10995    تكريم \"تُحفة مَناقب شرفاء وزان\" في جامعة فرنسية   \n",
       "10996  إسبانيا تردّ على المغرب بنشر طائرات \"إف 18\" فو...   \n",
       "10997    لجنة النموذج التنموي تضع \"ميثاق قواعد الاشتغال\"   \n",
       "10998  ضعف القدرات البشرية والبنيات المؤسساتية يبطئ ا...   \n",
       "10999     الشرطة تبرز خطوات تطوير الحياة المهنية الأمنية   \n",
       "\n",
       "                                 date                      author  \\\n",
       "0       الجمعة 02 أكتوبر 2020 - 23:19            هسبريس من الرباط   \n",
       "1       الجمعة 02 أكتوبر 2020 - 07:26            هسبريس من الرباط   \n",
       "2       الجمعة 02 أكتوبر 2020 - 04:00             عفيفة الحسينات*   \n",
       "3       الجمعة 02 أكتوبر 2020 - 02:00       حاورَها: وائل بورشاشن   \n",
       "4       الخميس 01 أكتوبر 2020 - 19:40            هسبريس من الرباط   \n",
       "...                               ...                         ...   \n",
       "10995  الثلاثاء 24 دجنبر 2019 - 20:05        هسبريس - مصطفى شاكري   \n",
       "10996  الثلاثاء 24 دجنبر 2019 - 18:00  هسبريس - عبد السلام الشامخ   \n",
       "10997  الثلاثاء 24 دجنبر 2019 - 13:15              هسبريس - و.م.ع   \n",
       "10998  الثلاثاء 24 دجنبر 2019 - 13:00          هسبريس - يوسف لخضر   \n",
       "10999  الثلاثاء 24 دجنبر 2019 - 12:33            هسبريس من الرباط   \n",
       "\n",
       "                                                   story           topic  \n",
       "0      وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...  art-et-culture  \n",
       "1      في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...  art-et-culture  \n",
       "2      تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...  art-et-culture  \n",
       "3      مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...  art-et-culture  \n",
       "4      أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...  art-et-culture  \n",
       "...                                                  ...             ...  \n",
       "10995  أطروحة جديدة تُعنى بدراسة الأبعاد السيميائية ل...         orbites  \n",
       "10996  تزامناً مع توجّه المغرب لترسيم حدوده في المياه...         orbites  \n",
       "10997  قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...         orbites  \n",
       "10998  اختُتمت، السبت الماضي بمدينة أكادير، أشغال الم...         orbites  \n",
       "10999  كشفت المديرية العامة للأمن الوطني عن حصيلة عمل...         orbites  \n",
       "\n",
       "[11000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a6efb",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e28ec3",
   "metadata": {},
   "source": [
    "## Convert The Date Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad4edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_arabic_to_english(arabic_date_str):\n",
    "    mapping = {\n",
    "        'السبت': 'Saturday', 'الأحد': 'Sunday', 'الاثنين': 'Monday', 'الثلاثاء': 'Tuesday',\n",
    "        'الأربعاء': 'Wednesday', 'الخميس': 'Thursday', 'الجمعة': 'Friday',\n",
    "        'يناير': 'January', 'فبراير': 'February', 'مارس': 'March', 'أبريل': 'April',\n",
    "        'ماي': 'May', 'يونيو': 'June', 'يوليوز': 'July', 'غشت': 'August',\n",
    "        'شتنبر': 'September', 'أكتوبر': 'October', 'نونبر': 'November', 'دجنبر': 'December'\n",
    "    }\n",
    "    \n",
    "    for key, value in mapping.items():\n",
    "        arabic_date_str = arabic_date_str.replace(key, value)\n",
    "    \n",
    "    return arabic_date_str\n",
    "\n",
    "df[\"date\"] = df[\"date\"].apply(convert_arabic_to_english)\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "\n",
    "df[\"date\"]  = pd.to_datetime(df[\"date\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca539e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f06aa998054e11eba66e646e69d991ea</td>\n",
       "      <td>\"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء</td>\n",
       "      <td>2020-10-02 23:19:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1cf1b9c054e11ebb718646e69d991ea</td>\n",
       "      <td>مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران</td>\n",
       "      <td>2020-10-02 07:26:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2d282a4054e11eb800f646e69d991ea</td>\n",
       "      <td>فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...</td>\n",
       "      <td>2020-10-02 04:00:00</td>\n",
       "      <td>عفيفة الحسينات*</td>\n",
       "      <td>تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f3f46cac054e11eba403646e69d991ea</td>\n",
       "      <td>\"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...</td>\n",
       "      <td>2020-10-02 02:00:00</td>\n",
       "      <td>حاورَها: وائل بورشاشن</td>\n",
       "      <td>مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f50f0476054e11eba31b646e69d991ea</td>\n",
       "      <td>مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"</td>\n",
       "      <td>2020-10-01 19:40:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>a74f908a055c11eb8ce2646e69d991ea</td>\n",
       "      <td>تكريم \"تُحفة مَناقب شرفاء وزان\" في جامعة فرنسية</td>\n",
       "      <td>2019-12-24 20:05:00</td>\n",
       "      <td>هسبريس - مصطفى شاكري</td>\n",
       "      <td>أطروحة جديدة تُعنى بدراسة الأبعاد السيميائية ل...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>a8579f76055c11eb9627646e69d991ea</td>\n",
       "      <td>إسبانيا تردّ على المغرب بنشر طائرات \"إف 18\" فو...</td>\n",
       "      <td>2019-12-24 18:00:00</td>\n",
       "      <td>هسبريس - عبد السلام الشامخ</td>\n",
       "      <td>تزامناً مع توجّه المغرب لترسيم حدوده في المياه...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>a9362062055c11ebaf97646e69d991ea</td>\n",
       "      <td>لجنة النموذج التنموي تضع \"ميثاق قواعد الاشتغال\"</td>\n",
       "      <td>2019-12-24 13:15:00</td>\n",
       "      <td>هسبريس - و.م.ع</td>\n",
       "      <td>قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>aa1cef2e055c11eb8ef8646e69d991ea</td>\n",
       "      <td>ضعف القدرات البشرية والبنيات المؤسساتية يبطئ ا...</td>\n",
       "      <td>2019-12-24 13:00:00</td>\n",
       "      <td>هسبريس - يوسف لخضر</td>\n",
       "      <td>اختُتمت، السبت الماضي بمدينة أكادير، أشغال الم...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>aabdd852055c11ebbba8646e69d991ea</td>\n",
       "      <td>الشرطة تبرز خطوات تطوير الحياة المهنية الأمنية</td>\n",
       "      <td>2019-12-24 12:33:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>كشفت المديرية العامة للأمن الوطني عن حصيلة عمل...</td>\n",
       "      <td>orbites</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0      f06aa998054e11eba66e646e69d991ea   \n",
       "1      f1cf1b9c054e11ebb718646e69d991ea   \n",
       "2      f2d282a4054e11eb800f646e69d991ea   \n",
       "3      f3f46cac054e11eba403646e69d991ea   \n",
       "4      f50f0476054e11eba31b646e69d991ea   \n",
       "...                                 ...   \n",
       "10995  a74f908a055c11eb8ce2646e69d991ea   \n",
       "10996  a8579f76055c11eb9627646e69d991ea   \n",
       "10997  a9362062055c11ebaf97646e69d991ea   \n",
       "10998  aa1cef2e055c11eb8ef8646e69d991ea   \n",
       "10999  aabdd852055c11ebbba8646e69d991ea   \n",
       "\n",
       "                                                   title                date  \\\n",
       "0         \"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء 2020-10-02 23:19:00   \n",
       "1           مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران 2020-10-02 07:26:00   \n",
       "2      فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا... 2020-10-02 04:00:00   \n",
       "3      \"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا... 2020-10-02 02:00:00   \n",
       "4            مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\" 2020-10-01 19:40:00   \n",
       "...                                                  ...                 ...   \n",
       "10995    تكريم \"تُحفة مَناقب شرفاء وزان\" في جامعة فرنسية 2019-12-24 20:05:00   \n",
       "10996  إسبانيا تردّ على المغرب بنشر طائرات \"إف 18\" فو... 2019-12-24 18:00:00   \n",
       "10997    لجنة النموذج التنموي تضع \"ميثاق قواعد الاشتغال\" 2019-12-24 13:15:00   \n",
       "10998  ضعف القدرات البشرية والبنيات المؤسساتية يبطئ ا... 2019-12-24 13:00:00   \n",
       "10999     الشرطة تبرز خطوات تطوير الحياة المهنية الأمنية 2019-12-24 12:33:00   \n",
       "\n",
       "                           author  \\\n",
       "0                هسبريس من الرباط   \n",
       "1                هسبريس من الرباط   \n",
       "2                 عفيفة الحسينات*   \n",
       "3           حاورَها: وائل بورشاشن   \n",
       "4                هسبريس من الرباط   \n",
       "...                           ...   \n",
       "10995        هسبريس - مصطفى شاكري   \n",
       "10996  هسبريس - عبد السلام الشامخ   \n",
       "10997              هسبريس - و.م.ع   \n",
       "10998          هسبريس - يوسف لخضر   \n",
       "10999            هسبريس من الرباط   \n",
       "\n",
       "                                                   story           topic  \n",
       "0      وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...  art-et-culture  \n",
       "1      في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...  art-et-culture  \n",
       "2      تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...  art-et-culture  \n",
       "3      مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...  art-et-culture  \n",
       "4      أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...  art-et-culture  \n",
       "...                                                  ...             ...  \n",
       "10995  أطروحة جديدة تُعنى بدراسة الأبعاد السيميائية ل...         orbites  \n",
       "10996  تزامناً مع توجّه المغرب لترسيم حدوده في المياه...         orbites  \n",
       "10997  قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...         orbites  \n",
       "10998  اختُتمت، السبت الماضي بمدينة أكادير، أشغال الم...         orbites  \n",
       "10999  كشفت المديرية العامة للأمن الوطني عن حصيلة عمل...         orbites  \n",
       "\n",
       "[11000 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573de928",
   "metadata": {},
   "source": [
    "## Drop ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73eb9259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"id\"], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5835f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000 entries, 0 to 10999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   title   11000 non-null  object        \n",
      " 1   date    11000 non-null  datetime64[ns]\n",
      " 2   author  11000 non-null  object        \n",
      " 3   story   11000 non-null  object        \n",
      " 4   topic   11000 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 429.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d2507",
   "metadata": {},
   "source": [
    "## Remove Very Long Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f6eb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column contain number of words in the story \n",
    "\n",
    "df['word_count'] = df['story'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95abbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the stories with more than 1500 words (Outliers)\n",
    "\n",
    "df_drop = df[df['word_count']>1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4097592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df_drop.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df920216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"word_count\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706bf513",
   "metadata": {},
   "source": [
    "## Arabic Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c31b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_arabic_stopwords(text):\n",
    "    \n",
    "    # tokenize the text into words\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Load the Arabic stopwords from NLTK\n",
    "    \n",
    "    arabic_stopwords = set(stopwords.words('arabic'))\n",
    "    words_without_stopwords = [word for word in words if word not in arabic_stopwords]\n",
    "    preprocessed_text = ' '.join(words_without_stopwords)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff67f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_story'] = df['story'].apply(remove_arabic_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c00dd",
   "metadata": {},
   "source": [
    "## Tashkel Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f7c3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_arabic_tashkel(text):\n",
    "    \n",
    "   # Remove non-Arabic characters\n",
    "\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
    "    \n",
    "    # Remove tashkel\n",
    "    \n",
    "    text_without_diacritics = strip_tashkeel(text)\n",
    "    return text_without_diacritics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c63dc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_story'] = df['preprocessed_story'].apply(remove_arabic_tashkel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05409fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "      <th>preprocessed_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء</td>\n",
       "      <td>2020-10-02 23:19:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>وجه  بيت الشعر المغرب  وزير الثقافة والشباب وا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران</td>\n",
       "      <td>2020-10-02 07:26:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>استمرار حالة الطوارئ الصحية المرتبطة بجائحة  ك...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...</td>\n",
       "      <td>2020-10-02 04:00:00</td>\n",
       "      <td>عفيفة الحسينات*</td>\n",
       "      <td>تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...</td>\n",
       "      <td>2020-10-02 02:00:00</td>\n",
       "      <td>حاورَها: وائل بورشاشن</td>\n",
       "      <td>مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>من قلب أيام  الحجر  ، رأت النور الفصول الأولى ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"</td>\n",
       "      <td>2020-10-01 19:40:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>أعلن الفنان المغربي سعيد مسكر تخليه مبلغ الدعم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>تكريم \"تُحفة مَناقب شرفاء وزان\" في جامعة فرنسية</td>\n",
       "      <td>2019-12-24 20:05:00</td>\n",
       "      <td>هسبريس - مصطفى شاكري</td>\n",
       "      <td>أطروحة جديدة تُعنى بدراسة الأبعاد السيميائية ل...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>أطروحة جديدة تعنى بدراسة الأبعاد السيميائية لل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>إسبانيا تردّ على المغرب بنشر طائرات \"إف 18\" فو...</td>\n",
       "      <td>2019-12-24 18:00:00</td>\n",
       "      <td>هسبريس - عبد السلام الشامخ</td>\n",
       "      <td>تزامناً مع توجّه المغرب لترسيم حدوده في المياه...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>تزامنا توجه المغرب لترسيم حدوده المياه الإقليم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>لجنة النموذج التنموي تضع \"ميثاق قواعد الاشتغال\"</td>\n",
       "      <td>2019-12-24 13:15:00</td>\n",
       "      <td>هسبريس - و.م.ع</td>\n",
       "      <td>قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>ضعف القدرات البشرية والبنيات المؤسساتية يبطئ ا...</td>\n",
       "      <td>2019-12-24 13:00:00</td>\n",
       "      <td>هسبريس - يوسف لخضر</td>\n",
       "      <td>اختُتمت، السبت الماضي بمدينة أكادير، أشغال الم...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>اختتمت، السبت الماضي بمدينة أكادير، أشغال المن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>الشرطة تبرز خطوات تطوير الحياة المهنية الأمنية</td>\n",
       "      <td>2019-12-24 12:33:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>كشفت المديرية العامة للأمن الوطني عن حصيلة عمل...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>كشفت المديرية العامة للأمن الوطني حصيلة عملها ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10836 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title                date  \\\n",
       "0         \"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء 2020-10-02 23:19:00   \n",
       "1           مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران 2020-10-02 07:26:00   \n",
       "2      فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا... 2020-10-02 04:00:00   \n",
       "3      \"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا... 2020-10-02 02:00:00   \n",
       "4            مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\" 2020-10-01 19:40:00   \n",
       "...                                                  ...                 ...   \n",
       "10995    تكريم \"تُحفة مَناقب شرفاء وزان\" في جامعة فرنسية 2019-12-24 20:05:00   \n",
       "10996  إسبانيا تردّ على المغرب بنشر طائرات \"إف 18\" فو... 2019-12-24 18:00:00   \n",
       "10997    لجنة النموذج التنموي تضع \"ميثاق قواعد الاشتغال\" 2019-12-24 13:15:00   \n",
       "10998  ضعف القدرات البشرية والبنيات المؤسساتية يبطئ ا... 2019-12-24 13:00:00   \n",
       "10999     الشرطة تبرز خطوات تطوير الحياة المهنية الأمنية 2019-12-24 12:33:00   \n",
       "\n",
       "                           author  \\\n",
       "0                هسبريس من الرباط   \n",
       "1                هسبريس من الرباط   \n",
       "2                 عفيفة الحسينات*   \n",
       "3           حاورَها: وائل بورشاشن   \n",
       "4                هسبريس من الرباط   \n",
       "...                           ...   \n",
       "10995        هسبريس - مصطفى شاكري   \n",
       "10996  هسبريس - عبد السلام الشامخ   \n",
       "10997              هسبريس - و.م.ع   \n",
       "10998          هسبريس - يوسف لخضر   \n",
       "10999            هسبريس من الرباط   \n",
       "\n",
       "                                                   story           topic  \\\n",
       "0      وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...  art-et-culture   \n",
       "1      في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...  art-et-culture   \n",
       "2      تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...  art-et-culture   \n",
       "3      مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...  art-et-culture   \n",
       "4      أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...  art-et-culture   \n",
       "...                                                  ...             ...   \n",
       "10995  أطروحة جديدة تُعنى بدراسة الأبعاد السيميائية ل...         orbites   \n",
       "10996  تزامناً مع توجّه المغرب لترسيم حدوده في المياه...         orbites   \n",
       "10997  قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...         orbites   \n",
       "10998  اختُتمت، السبت الماضي بمدينة أكادير، أشغال الم...         orbites   \n",
       "10999  كشفت المديرية العامة للأمن الوطني عن حصيلة عمل...         orbites   \n",
       "\n",
       "                                      preprocessed_story  \n",
       "0      وجه  بيت الشعر المغرب  وزير الثقافة والشباب وا...  \n",
       "1      استمرار حالة الطوارئ الصحية المرتبطة بجائحة  ك...  \n",
       "2      تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...  \n",
       "3      من قلب أيام  الحجر  ، رأت النور الفصول الأولى ...  \n",
       "4      أعلن الفنان المغربي سعيد مسكر تخليه مبلغ الدعم...  \n",
       "...                                                  ...  \n",
       "10995  أطروحة جديدة تعنى بدراسة الأبعاد السيميائية لل...  \n",
       "10996  تزامنا توجه المغرب لترسيم حدوده المياه الإقليم...  \n",
       "10997  قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...  \n",
       "10998  اختتمت، السبت الماضي بمدينة أكادير، أشغال المن...  \n",
       "10999  كشفت المديرية العامة للأمن الوطني حصيلة عملها ...  \n",
       "\n",
       "[10836 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4bbca",
   "metadata": {},
   "source": [
    "## Bi-Gram Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b00f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_gram_tokenization(text):\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Create bi-grams from the words\n",
    "    \n",
    "    bi_grams = list(ngrams(words, 2))\n",
    "    bi_gram_text = ' '.join([' '.join(bi_gram) for bi_gram in bi_grams])\n",
    "    \n",
    "    return bi_gram_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add5820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_story'] = df['preprocessed_story'].apply(bi_gram_tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4345803e",
   "metadata": {},
   "source": [
    "## Word Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27141142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec word embeddings\n",
    "\n",
    "sentences = [nltk.word_tokenize(story) for story in df['preprocessed_story']]\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bca7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the vector representation of a sentence\n",
    "\n",
    "def get_sentence_vector(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    vector_sum = sum(model.wv[word] for word in words if word in model.wv)\n",
    "    return vector_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f99aa8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectors for the preprocessed stories\n",
    "\n",
    "df['story_vector'] = df['preprocessed_story'].apply(get_sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a41e06c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "      <th>preprocessed_story</th>\n",
       "      <th>story_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء</td>\n",
       "      <td>2020-10-02 23:19:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>وجه بيت بيت الشعر الشعر المغرب المغرب وزير وزي...</td>\n",
       "      <td>[-72.74186, 348.1042, -338.5879, 791.9453, 300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران</td>\n",
       "      <td>2020-10-02 07:26:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>استمرار حالة حالة الطوارئ الطوارئ الصحية الصحي...</td>\n",
       "      <td>[32.7332, 127.126755, -190.36511, 423.89313, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...</td>\n",
       "      <td>2020-10-02 04:00:00</td>\n",
       "      <td>عفيفة الحسينات*</td>\n",
       "      <td>تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>تشير مشاهدة مشاهدة فيلم فيلم قصير قصير ضمن ضمن...</td>\n",
       "      <td>[93.74494, 102.065796, -218.77057, 423.1378, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...</td>\n",
       "      <td>2020-10-02 02:00:00</td>\n",
       "      <td>حاورَها: وائل بورشاشن</td>\n",
       "      <td>مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>من قلب قلب أيام أيام الحجر الحجر ، ، رأت رأت ا...</td>\n",
       "      <td>[131.1908, 44.807434, -240.14757, 540.2877, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"</td>\n",
       "      <td>2020-10-01 19:40:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...</td>\n",
       "      <td>art-et-culture</td>\n",
       "      <td>أعلن الفنان الفنان المغربي المغربي سعيد سعيد م...</td>\n",
       "      <td>[26.834738, 4.3731627, -117.5887, 180.85771, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>تكريم \"تُحفة مَناقب شرفاء وزان\" في جامعة فرنسية</td>\n",
       "      <td>2019-12-24 20:05:00</td>\n",
       "      <td>هسبريس - مصطفى شاكري</td>\n",
       "      <td>أطروحة جديدة تُعنى بدراسة الأبعاد السيميائية ل...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>أطروحة جديدة جديدة تعنى تعنى بدراسة بدراسة الأ...</td>\n",
       "      <td>[51.17661, 178.2686, -246.8917, 441.59705, 49....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>إسبانيا تردّ على المغرب بنشر طائرات \"إف 18\" فو...</td>\n",
       "      <td>2019-12-24 18:00:00</td>\n",
       "      <td>هسبريس - عبد السلام الشامخ</td>\n",
       "      <td>تزامناً مع توجّه المغرب لترسيم حدوده في المياه...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>تزامنا توجه توجه المغرب المغرب لترسيم لترسيم ح...</td>\n",
       "      <td>[-54.778965, 269.9183, -70.60175, 307.7276, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>لجنة النموذج التنموي تضع \"ميثاق قواعد الاشتغال\"</td>\n",
       "      <td>2019-12-24 13:15:00</td>\n",
       "      <td>هسبريس - و.م.ع</td>\n",
       "      <td>قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>قامت اللجنة اللجنة الخاصة الخاصة بالنموذج بالن...</td>\n",
       "      <td>[36.508644, -38.15644, -28.715273, 199.49873, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>ضعف القدرات البشرية والبنيات المؤسساتية يبطئ ا...</td>\n",
       "      <td>2019-12-24 13:00:00</td>\n",
       "      <td>هسبريس - يوسف لخضر</td>\n",
       "      <td>اختُتمت، السبت الماضي بمدينة أكادير، أشغال الم...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>اختتمت، السبت السبت الماضي الماضي بمدينة بمدين...</td>\n",
       "      <td>[65.237686, -19.095953, -218.21838, 413.7935, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>الشرطة تبرز خطوات تطوير الحياة المهنية الأمنية</td>\n",
       "      <td>2019-12-24 12:33:00</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>كشفت المديرية العامة للأمن الوطني عن حصيلة عمل...</td>\n",
       "      <td>orbites</td>\n",
       "      <td>كشفت المديرية المديرية العامة العامة للأمن للأ...</td>\n",
       "      <td>[-39.935764, 119.48839, 373.58563, 460.0485, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10836 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title                date  \\\n",
       "0         \"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء 2020-10-02 23:19:00   \n",
       "1           مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران 2020-10-02 07:26:00   \n",
       "2      فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا... 2020-10-02 04:00:00   \n",
       "3      \"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا... 2020-10-02 02:00:00   \n",
       "4            مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\" 2020-10-01 19:40:00   \n",
       "...                                                  ...                 ...   \n",
       "10995    تكريم \"تُحفة مَناقب شرفاء وزان\" في جامعة فرنسية 2019-12-24 20:05:00   \n",
       "10996  إسبانيا تردّ على المغرب بنشر طائرات \"إف 18\" فو... 2019-12-24 18:00:00   \n",
       "10997    لجنة النموذج التنموي تضع \"ميثاق قواعد الاشتغال\" 2019-12-24 13:15:00   \n",
       "10998  ضعف القدرات البشرية والبنيات المؤسساتية يبطئ ا... 2019-12-24 13:00:00   \n",
       "10999     الشرطة تبرز خطوات تطوير الحياة المهنية الأمنية 2019-12-24 12:33:00   \n",
       "\n",
       "                           author  \\\n",
       "0                هسبريس من الرباط   \n",
       "1                هسبريس من الرباط   \n",
       "2                 عفيفة الحسينات*   \n",
       "3           حاورَها: وائل بورشاشن   \n",
       "4                هسبريس من الرباط   \n",
       "...                           ...   \n",
       "10995        هسبريس - مصطفى شاكري   \n",
       "10996  هسبريس - عبد السلام الشامخ   \n",
       "10997              هسبريس - و.م.ع   \n",
       "10998          هسبريس - يوسف لخضر   \n",
       "10999            هسبريس من الرباط   \n",
       "\n",
       "                                                   story           topic  \\\n",
       "0      وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...  art-et-culture   \n",
       "1      في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...  art-et-culture   \n",
       "2      تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...  art-et-culture   \n",
       "3      مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...  art-et-culture   \n",
       "4      أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...  art-et-culture   \n",
       "...                                                  ...             ...   \n",
       "10995  أطروحة جديدة تُعنى بدراسة الأبعاد السيميائية ل...         orbites   \n",
       "10996  تزامناً مع توجّه المغرب لترسيم حدوده في المياه...         orbites   \n",
       "10997  قامت اللجنة الخاصة بالنموذج التنموي، خلال اجتم...         orbites   \n",
       "10998  اختُتمت، السبت الماضي بمدينة أكادير، أشغال الم...         orbites   \n",
       "10999  كشفت المديرية العامة للأمن الوطني عن حصيلة عمل...         orbites   \n",
       "\n",
       "                                      preprocessed_story  \\\n",
       "0      وجه بيت بيت الشعر الشعر المغرب المغرب وزير وزي...   \n",
       "1      استمرار حالة حالة الطوارئ الطوارئ الصحية الصحي...   \n",
       "2      تشير مشاهدة مشاهدة فيلم فيلم قصير قصير ضمن ضمن...   \n",
       "3      من قلب قلب أيام أيام الحجر الحجر ، ، رأت رأت ا...   \n",
       "4      أعلن الفنان الفنان المغربي المغربي سعيد سعيد م...   \n",
       "...                                                  ...   \n",
       "10995  أطروحة جديدة جديدة تعنى تعنى بدراسة بدراسة الأ...   \n",
       "10996  تزامنا توجه توجه المغرب المغرب لترسيم لترسيم ح...   \n",
       "10997  قامت اللجنة اللجنة الخاصة الخاصة بالنموذج بالن...   \n",
       "10998  اختتمت، السبت السبت الماضي الماضي بمدينة بمدين...   \n",
       "10999  كشفت المديرية المديرية العامة العامة للأمن للأ...   \n",
       "\n",
       "                                            story_vector  \n",
       "0      [-72.74186, 348.1042, -338.5879, 791.9453, 300...  \n",
       "1      [32.7332, 127.126755, -190.36511, 423.89313, 4...  \n",
       "2      [93.74494, 102.065796, -218.77057, 423.1378, 1...  \n",
       "3      [131.1908, 44.807434, -240.14757, 540.2877, 21...  \n",
       "4      [26.834738, 4.3731627, -117.5887, 180.85771, 1...  \n",
       "...                                                  ...  \n",
       "10995  [51.17661, 178.2686, -246.8917, 441.59705, 49....  \n",
       "10996  [-54.778965, 269.9183, -70.60175, 307.7276, 14...  \n",
       "10997  [36.508644, -38.15644, -28.715273, 199.49873, ...  \n",
       "10998  [65.237686, -19.095953, -218.21838, 413.7935, ...  \n",
       "10999  [-39.935764, 119.48839, 373.58563, 460.0485, -...  \n",
       "\n",
       "[10836 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ab8fa",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dacd04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(df['topic'])\n",
    "\n",
    "df['topic_encoded'] = label_encoder.transform(df['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fd3b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'art-et-culture': 0, 'economie': 1, 'faits-divers': 2, 'marocains-du-monde': 3, 'medias': 4, 'orbites': 5, 'politique': 6, 'regions': 7, 'societe': 8, 'sport': 9, 'tamazight': 10}\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d652f79",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d988f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to store the train and test indices\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "groups = df.groupby('topic_encoded')\n",
    "for _, group in groups:\n",
    "    num_samples = len(group)\n",
    "    train_size = int(num_samples * 0.8)\n",
    "    indices = group.index.tolist()\n",
    "    train_indices.extend(indices[:train_size])\n",
    "    test_indices.extend(indices[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87778cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train and test sets by the indices\n",
    "\n",
    "training_data = df.loc[train_indices]\n",
    "testing_data = df.loc[test_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0c98e",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80472d4",
   "metadata": {},
   "source": [
    "## Deep Learning Method RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31a54800",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data['story_vector']\n",
    "y_train = training_data['topic_encoded']\n",
    "\n",
    "X_test = testing_data['story_vector']\n",
    "y_test = testing_data['topic_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c0d0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert word embeddings to numpy arrays \n",
    "\n",
    "X_train = np.array(X_train.tolist())\n",
    "X_test = np.array(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3a1fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the input sequences\n",
    "\n",
    "max_sequence_length = X_train.shape[1]  \n",
    "\n",
    "# Number of unique topics\n",
    "\n",
    "num_classes = len(np.unique(y_train))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1d2bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN(LSTM) model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=X_train.shape[0], output_dim=max_sequence_length, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23c365d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - loss: {logs['loss']:.4f} - accuracy: {logs['accuracy']:.4f}\")\n",
    "\n",
    "epochs = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e53f5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - loss: 2.3418 - accuracy: 0.1332\n",
      "Epoch 2/100 - loss: 2.2487 - accuracy: 0.1873\n",
      "Epoch 3/100 - loss: 2.1713 - accuracy: 0.2248\n",
      "Epoch 4/100 - loss: 2.1124 - accuracy: 0.2473\n",
      "Epoch 5/100 - loss: 2.0422 - accuracy: 0.2774\n",
      "Epoch 6/100 - loss: 1.9628 - accuracy: 0.3089\n",
      "Epoch 7/100 - loss: 1.9035 - accuracy: 0.3383\n",
      "Epoch 8/100 - loss: 1.8244 - accuracy: 0.3713\n",
      "Epoch 9/100 - loss: 1.7416 - accuracy: 0.4042\n",
      "Epoch 10/100 - loss: 1.6743 - accuracy: 0.4294\n",
      "Epoch 11/100 - loss: 1.5974 - accuracy: 0.4649\n",
      "Epoch 12/100 - loss: 1.5252 - accuracy: 0.4885\n",
      "Epoch 13/100 - loss: 1.4445 - accuracy: 0.5245\n",
      "Epoch 14/100 - loss: 1.3686 - accuracy: 0.5514\n",
      "Epoch 15/100 - loss: 1.3063 - accuracy: 0.5758\n",
      "Epoch 16/100 - loss: 1.2234 - accuracy: 0.6016\n",
      "Epoch 17/100 - loss: 1.1805 - accuracy: 0.6170\n",
      "Epoch 18/100 - loss: 1.1178 - accuracy: 0.6361\n",
      "Epoch 19/100 - loss: 1.0424 - accuracy: 0.6658\n",
      "Epoch 20/100 - loss: 1.0233 - accuracy: 0.6695\n",
      "Epoch 21/100 - loss: 0.9434 - accuracy: 0.6954\n",
      "Epoch 22/100 - loss: 0.8936 - accuracy: 0.7200\n",
      "Epoch 23/100 - loss: 0.8542 - accuracy: 0.7329\n",
      "Epoch 24/100 - loss: 0.8231 - accuracy: 0.7389\n",
      "Epoch 25/100 - loss: 0.7837 - accuracy: 0.7552\n",
      "Epoch 26/100 - loss: 0.7253 - accuracy: 0.7699\n",
      "Epoch 27/100 - loss: 0.6715 - accuracy: 0.7897\n",
      "Epoch 28/100 - loss: 0.6530 - accuracy: 0.7991\n",
      "Epoch 29/100 - loss: 0.6360 - accuracy: 0.8031\n",
      "Epoch 30/100 - loss: 0.5688 - accuracy: 0.8225\n",
      "Epoch 31/100 - loss: 0.5490 - accuracy: 0.8319\n",
      "Epoch 32/100 - loss: 0.5464 - accuracy: 0.8305\n",
      "Epoch 33/100 - loss: 0.5106 - accuracy: 0.8437\n",
      "Epoch 34/100 - loss: 0.4754 - accuracy: 0.8548\n",
      "Epoch 35/100 - loss: 0.4482 - accuracy: 0.8641\n",
      "Epoch 36/100 - loss: 0.4457 - accuracy: 0.8608\n",
      "Epoch 37/100 - loss: 0.4216 - accuracy: 0.8689\n",
      "Epoch 38/100 - loss: 0.3935 - accuracy: 0.8815\n",
      "Epoch 39/100 - loss: 0.3475 - accuracy: 0.8949\n",
      "Epoch 40/100 - loss: 0.3503 - accuracy: 0.8937\n",
      "Epoch 41/100 - loss: 0.3371 - accuracy: 0.8961\n",
      "Epoch 42/100 - loss: 0.3728 - accuracy: 0.8841\n",
      "Epoch 43/100 - loss: 0.3314 - accuracy: 0.8950\n",
      "Epoch 44/100 - loss: 0.2808 - accuracy: 0.9143\n",
      "Epoch 45/100 - loss: 0.2916 - accuracy: 0.9088\n",
      "Epoch 46/100 - loss: 0.3120 - accuracy: 0.9016\n",
      "Epoch 47/100 - loss: 0.2875 - accuracy: 0.9091\n",
      "Epoch 48/100 - loss: 0.2705 - accuracy: 0.9204\n",
      "Epoch 49/100 - loss: 0.2261 - accuracy: 0.9303\n",
      "Epoch 50/100 - loss: 0.2057 - accuracy: 0.9406\n",
      "Epoch 51/100 - loss: 0.2167 - accuracy: 0.9343\n",
      "Epoch 52/100 - loss: 0.2129 - accuracy: 0.9361\n",
      "Epoch 53/100 - loss: 0.2449 - accuracy: 0.9244\n",
      "Epoch 54/100 - loss: 0.1851 - accuracy: 0.9439\n",
      "Epoch 55/100 - loss: 0.2357 - accuracy: 0.9283\n",
      "Epoch 56/100 - loss: 0.2098 - accuracy: 0.9362\n",
      "Epoch 57/100 - loss: 0.1815 - accuracy: 0.9429\n",
      "Epoch 58/100 - loss: 0.1792 - accuracy: 0.9467\n",
      "Epoch 59/100 - loss: 0.1379 - accuracy: 0.9601\n",
      "Epoch 60/100 - loss: 0.1325 - accuracy: 0.9606\n",
      "Epoch 61/100 - loss: 0.1584 - accuracy: 0.9537\n",
      "Epoch 62/100 - loss: 0.1570 - accuracy: 0.9543\n",
      "Epoch 63/100 - loss: 0.2046 - accuracy: 0.9355\n",
      "Epoch 64/100 - loss: 0.1414 - accuracy: 0.9552\n",
      "Epoch 65/100 - loss: 0.1504 - accuracy: 0.9548\n",
      "Epoch 66/100 - loss: 0.1452 - accuracy: 0.9579\n",
      "Epoch 67/100 - loss: 0.1259 - accuracy: 0.9620\n",
      "Epoch 68/100 - loss: 0.1657 - accuracy: 0.9497\n",
      "Epoch 69/100 - loss: 0.1256 - accuracy: 0.9641\n",
      "Epoch 70/100 - loss: 0.1067 - accuracy: 0.9702\n",
      "Epoch 71/100 - loss: 0.1284 - accuracy: 0.9611\n",
      "Epoch 72/100 - loss: 0.1365 - accuracy: 0.9600\n",
      "Epoch 73/100 - loss: 0.1098 - accuracy: 0.9672\n",
      "Epoch 74/100 - loss: 0.0888 - accuracy: 0.9752\n",
      "Epoch 75/100 - loss: 0.0765 - accuracy: 0.9766\n",
      "Epoch 76/100 - loss: 0.1098 - accuracy: 0.9688\n",
      "Epoch 77/100 - loss: 0.1134 - accuracy: 0.9670\n",
      "Epoch 78/100 - loss: 0.1589 - accuracy: 0.9534\n",
      "Epoch 79/100 - loss: 0.0974 - accuracy: 0.9709\n",
      "Epoch 80/100 - loss: 0.1007 - accuracy: 0.9705\n",
      "Epoch 81/100 - loss: 0.0761 - accuracy: 0.9766\n",
      "Epoch 82/100 - loss: 0.1384 - accuracy: 0.9585\n",
      "Epoch 83/100 - loss: 0.1074 - accuracy: 0.9694\n",
      "Epoch 84/100 - loss: 0.0802 - accuracy: 0.9771\n",
      "Epoch 85/100 - loss: 0.0599 - accuracy: 0.9833\n",
      "Epoch 86/100 - loss: 0.1067 - accuracy: 0.9676\n",
      "Epoch 87/100 - loss: 0.0783 - accuracy: 0.9759\n",
      "Epoch 88/100 - loss: 0.0495 - accuracy: 0.9862\n",
      "Epoch 89/100 - loss: 0.0783 - accuracy: 0.9775\n",
      "Epoch 90/100 - loss: 0.1481 - accuracy: 0.9537\n",
      "Epoch 91/100 - loss: 0.1152 - accuracy: 0.9671\n",
      "Epoch 92/100 - loss: 0.0791 - accuracy: 0.9760\n",
      "Epoch 93/100 - loss: 0.0426 - accuracy: 0.9896\n",
      "Epoch 94/100 - loss: 0.0698 - accuracy: 0.9807\n",
      "Epoch 95/100 - loss: 0.0746 - accuracy: 0.9785\n",
      "Epoch 96/100 - loss: 0.0537 - accuracy: 0.9845\n",
      "Epoch 97/100 - loss: 0.0873 - accuracy: 0.9747\n",
      "Epoch 98/100 - loss: 0.1068 - accuracy: 0.9678\n",
      "Epoch 99/100 - loss: 0.1151 - accuracy: 0.9678\n",
      "Epoch 100/100 - loss: 0.0741 - accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64, verbose=0, callbacks=[LossHistory()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5ea1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test set\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14ce5f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    art-et-culture       0.36      0.40      0.38       196\n",
      "          economie       0.38      0.29      0.33       200\n",
      "      faits-divers       0.70      0.72      0.71       200\n",
      "marocains-du-monde       0.24      0.25      0.24       200\n",
      "            medias       0.24      0.27      0.25       199\n",
      "           orbites       0.15      0.19      0.17       183\n",
      "         politique       0.34      0.32      0.33       200\n",
      "           regions       0.41      0.38      0.39       200\n",
      "           societe       0.23      0.24      0.24       200\n",
      "             sport       0.62      0.47      0.53       200\n",
      "         tamazight       0.32      0.33      0.32       193\n",
      "\n",
      "          accuracy                           0.35      2171\n",
      "         macro avg       0.36      0.35      0.36      2171\n",
      "      weighted avg       0.37      0.35      0.36      2171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report\n",
    "\n",
    "target_names = ['art-et-culture', 'economie', 'faits-divers', 'marocains-du-monde', 'medias', 'orbites', 'politique', 'regions', 'societe', 'sport', 'tamazight']\n",
    "\n",
    "report = classification_report(y_test, y_pred_classes, target_names=target_names)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f8715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d301604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0adb181",
   "metadata": {},
   "source": [
    "## Transformer-based Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0deb550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdalrhman Morsi\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2ForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4609873",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data['story']\n",
    "y_train = training_data['topic_encoded']\n",
    "\n",
    "X_test = testing_data['story']\n",
    "y_test = testing_data['topic_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a71739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GPT-2 tokenizer and encode the text data\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', do_lower_case=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "X_train_encodings = tokenizer(list(X_train), truncation=True, padding=True, return_tensors='tf')\n",
    "X_test_encodings = tokenizer(list(X_test), truncation=True, padding=True, return_tensors='tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "457ccf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 548M/548M [02:31<00:00, 3.62MB/s] \n",
      "Loading a PyTorch model in TensorFlow, requires both PyTorch and TensorFlow to be installed. Please see https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 3: Initialize the GPT-2 model for sequence classification\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFGPT2ForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 4: Compile the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m), loss\u001b[38;5;241m=\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), metrics\u001b[38;5;241m=\u001b[39m[SparseCategoricalAccuracy()])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\modeling_tf_utils.py:2880\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2877\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_checkpoint_in_tf2_model\n\u001b[0;32m   2879\u001b[0m     \u001b[38;5;66;03m# Load from a PyTorch checkpoint\u001b[39;00m\n\u001b[1;32m-> 2880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_pytorch_checkpoint_in_tf2_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_missing_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2884\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_loading_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_loading_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2885\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_weight_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;66;03m# we might need to extend the variable scope for composite models\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_weight_prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\modeling_tf_pytorch_utils.py:168\u001b[0m, in \u001b[0;36mload_pytorch_checkpoint_in_tf2_model\u001b[1;34m(tf_model, pytorch_checkpoint_path, tf_inputs, allow_missing_keys, output_loading_info, _prefix, tf_to_pt_weight_rename)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a PyTorch model in TensorFlow, requires both PyTorch and TensorFlow to be installed. Please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Initialize the GPT-2 model for sequence classification\n",
    "\n",
    "model = TFGPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=len(np.unique(y_train)), from_pt= True)\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=2e-5), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[SparseCategoricalAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6f5c6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported value type BatchEncoding returned by IteratorSpec._serialize",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 5: Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# You can adjust the number of epochs based on your computational resources\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    763\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3066\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3421\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3418\u001b[0m   flat_args, filtered_flat_args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m], []\n\u001b[0;32m   3420\u001b[0m cache_key_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_key_context()\n\u001b[1;32m-> 3421\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_key_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3423\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3424\u001b[0m   \u001b[38;5;28mhash\u001b[39m(cache_key)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3202\u001b[0m, in \u001b[0;36mFunction._cache_key\u001b[1;34m(self, args, kwargs, cache_key_context, include_tensor_ranks_only)\u001b[0m\n\u001b[0;32m   3199\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m (args, kwargs)\n\u001b[0;32m   3200\u001b[0m   input_signature \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_EncodeArg(inputs,\n\u001b[0;32m   3201\u001b[0m                                                 include_tensor_ranks_only)\n\u001b[1;32m-> 3202\u001b[0m   hashable_input_signature \u001b[38;5;241m=\u001b[39m \u001b[43m_make_input_signature_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_signature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3204\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m args, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:114\u001b[0m, in \u001b[0;36m_make_input_signature_hashable\u001b[1;34m(elem)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Rewrite input signature to be hashable.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mWe replace nested variables in the input signature with TensorSpec in order to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m  A hashable object for the requested input signature\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m   \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): consider using nest.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:329\u001b[0m, in \u001b[0;36mTypeSpec.__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:367\u001b[0m, in \u001b[0;36mTypeSpec.__get_cmp_key\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# TODO(b/133606651): Decide whether to cache this value.\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__make_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:385\u001b[0m, in \u001b[0;36mTypeSpec.__make_cmp_key\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[0;32m    380\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[0;32m    381\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[0;32m    382\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    383\u001b[0m   ])\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:385\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[0;32m    380\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[0;32m    381\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[0;32m    382\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    383\u001b[0m   ])\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__make_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:385\u001b[0m, in \u001b[0;36mTypeSpec.__make_cmp_key\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[0;32m    380\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[0;32m    381\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[0;32m    382\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    383\u001b[0m   ])\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:385\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[0;32m    380\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[0;32m    381\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[0;32m    382\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    383\u001b[0m   ])\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__make_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:397\u001b[0m, in \u001b[0;36mTypeSpec.__make_cmp_key\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mndarray, value\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m    396\u001b[0m           TypeSpec\u001b[38;5;241m.\u001b[39m__nested_list_to_tuple(value\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m--> 397\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported value type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m returned by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m._serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    399\u001b[0m                  (\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported value type BatchEncoding returned by IteratorSpec._serialize"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "epochs = 3  \n",
    "history = model.fit(x=X_train_encodings, y=y_train, validation_data=(X_test_encodings, y_test), epochs=epochs, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_encodings, y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c17104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd92879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0a8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c796f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33dddfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d028a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edef416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80100700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a72bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "X_train_encodings = tokenizer(list(X_train), truncation=True, padding=True, return_tensors='tf')\n",
    "X_test_encodings = tokenizer(list(X_test), truncation=True, padding=True, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff05a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b6e02d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 440M/440M [02:07<00:00, 3.45MB/s] \n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(np.unique(y_train)))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=2e-5), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[SparseCategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59d17e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported value type BatchEncoding returned by IteratorSpec._serialize",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 5: Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# You can adjust the number of epochs based on your computational resources\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    763\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3066\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3421\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3418\u001b[0m   flat_args, filtered_flat_args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m], []\n\u001b[0;32m   3420\u001b[0m cache_key_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_key_context()\n\u001b[1;32m-> 3421\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_key_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3423\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3424\u001b[0m   \u001b[38;5;28mhash\u001b[39m(cache_key)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3202\u001b[0m, in \u001b[0;36mFunction._cache_key\u001b[1;34m(self, args, kwargs, cache_key_context, include_tensor_ranks_only)\u001b[0m\n\u001b[0;32m   3199\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m (args, kwargs)\n\u001b[0;32m   3200\u001b[0m   input_signature \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_EncodeArg(inputs,\n\u001b[0;32m   3201\u001b[0m                                                 include_tensor_ranks_only)\n\u001b[1;32m-> 3202\u001b[0m   hashable_input_signature \u001b[38;5;241m=\u001b[39m \u001b[43m_make_input_signature_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_signature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3204\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m args, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:114\u001b[0m, in \u001b[0;36m_make_input_signature_hashable\u001b[1;34m(elem)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Rewrite input signature to be hashable.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mWe replace nested variables in the input signature with TensorSpec in order to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m  A hashable object for the requested input signature\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m   \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): consider using nest.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:329\u001b[0m, in \u001b[0;36mTypeSpec.__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:367\u001b[0m, in \u001b[0;36mTypeSpec.__get_cmp_key\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# TODO(b/133606651): Decide whether to cache this value.\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__make_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:385\u001b[0m, in \u001b[0;36mTypeSpec.__make_cmp_key\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[0;32m    380\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[0;32m    381\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[0;32m    382\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    383\u001b[0m   ])\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:385\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[0;32m    380\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[0;32m    381\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[0;32m    382\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    383\u001b[0m   ])\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__make_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:385\u001b[0m, in \u001b[0;36mTypeSpec.__make_cmp_key\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[0;32m    380\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[0;32m    381\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[0;32m    382\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    383\u001b[0m   ])\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:385\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[0;32m    380\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[0;32m    381\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[0;32m    382\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    383\u001b[0m   ])\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__make_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:397\u001b[0m, in \u001b[0;36mTypeSpec.__make_cmp_key\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mndarray, value\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m    396\u001b[0m           TypeSpec\u001b[38;5;241m.\u001b[39m__nested_list_to_tuple(value\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m--> 397\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported value type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m returned by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m._serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    399\u001b[0m                  (\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported value type BatchEncoding returned by IteratorSpec._serialize"
     ]
    }
   ],
   "source": [
    "epochs = 3  \n",
    "history = model.fit(x=X_train_encodings, y=y_train, validation_data=(X_test_encodings, y_test), epochs=epochs, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeeb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_encodings, y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ded11",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['art-et-culture', 'economie', 'faits-divers', 'marocains-du-monde', 'medias', 'orbites', 'politique', 'regions', 'societe', 'sport', 'tamazight']\n",
    "report = classification_report(y_test, y_pred_classes, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c27a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
